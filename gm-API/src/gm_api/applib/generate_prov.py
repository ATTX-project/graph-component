import requests
import falcon
import random
from rdflib import Graph, BNode, URIRef, Literal
from rdflib.namespace import DC, RDF, XSD
from gm_api.utils.prefixes import bind_prefix, ATTXBase, ATTXOnto, ATTXProv, PROV, PWO, SD
from gm_api.utils.logs import app_logger

artifact = 'gm_API'  # Define the ETL agent
agent = 'ETL'  # Define Agent type


def update_linking_provenance(endpoint, startTime, endTime, generatedDataset, usedDatasetList=None):
    """Update provenance graph in the graph store."""
    graph = Graph()
    bind_prefix(graph)
    try:
        workflow_provenance(graph)
        activity_provenance(graph, startTime, endTime, generatedDataset, usedDatasetList)
        store_api = "http://{0}:{1}/{2}/data?graph={3}".format(endpoint['host'], endpoint['port'], endpoint['dataset'], ATTXProv)
        headers = {'Content-Type': 'text/turtle'}
        result = requests.post(store_api, data=graph.serialize(format='turtle'), headers=headers)
        app_logger.info('Add to graph store: "{0}" the result of the linking strategy.'.format(ATTXProv))
        return result.status_code
    except Exception as error:
        app_logger.error('Something is wrong: {0}'.format(error))
        raise falcon.HTTPUnprocessableEntity(
            'Unprocessable Graph generated by strategy',
            'Could not update graph store with the graph generated by the strategy.'
        )


def activity_provenance(graph, startTime, endTime, generatedDataset, usedDatasetList=None):
    """Generate activity related provenance for link endpoint."""
    bnode = BNode()
    activity_id = str(random.randint(1e15, 1e16))
    workflow_id = "_link"

    graph.add((URIRef("{0}activity{1}".format(ATTXBase, activity_id)), RDF.type, PROV.Activity))
    graph.add((URIRef("{0}activity{1}".format(ATTXBase, activity_id)), RDF.type, ATTXOnto.WorkflowExecution))
    graph.add((URIRef("{0}activity{1}".format(ATTXBase, activity_id)), PROV.startedAtTime, Literal(startTime, datatype=XSD.dateTime)))
    graph.add((URIRef("{0}activity{1}".format(ATTXBase, activity_id)), PROV.endedAtTime, Literal(endTime, datatype=XSD.dateTime)))
    graph.add((URIRef("{0}activity{1}".format(ATTXBase, activity_id)), PROV.qualifiedAssociation, bnode))
    graph.add((bnode, RDF.type, PROV.Assocation))
    graph.add((bnode, PROV.hadPlan, URIRef("{0}workflow{1}".format(ATTXBase, workflow_id))))
    graph.add((bnode, PROV.agent, URIRef("{0}{1}".format(ATTXBase, agent))))
    graph.add((URIRef("{0}{1}".format(ATTXBase, agent)), RDF.type, PROV.Agent))
    # information about the agent and the artifact used.
    graph.add((URIRef("{0}{1}".format(ATTXBase, agent)), ATTXOnto.usesArtifact, URIRef("{0}{1}".format(ATTXBase, artifact))))
    if usedDatasetList is not None:
        for dataset in usedDatasetList:
            dataset_provenance(graph, dataset, activity_id, "used")
    dataset_provenance(graph, str(generatedDataset), activity_id, "generated")
    app_logger.info('Construct activity metadata for Activity: activity{0}.' .format(activity_id))
    return graph


def dataset_provenance(graph, dataset, activityID, datasetType):
    """Generate datasets associated to the provenance."""
    graph.add((URIRef(dataset), RDF.type, ATTXOnto.Dataset))
    graph.add((URIRef(dataset), RDF.type, SD.Dataset))
    if datasetType == "used":
        graph.add((URIRef("{0}activity{1}".format(ATTXBase, activityID)), PROV.used, URIRef(dataset)))
    elif datasetType == "generated":
        graph.add((URIRef("{0}activity{1}".format(ATTXBase, activityID)), PROV.generated, URIRef(dataset)))
        graph.add((URIRef(dataset), DC.title, Literal("activity{0} Linking Dataset".format(activityID))))
        graph.add((URIRef(dataset), DC.description, Literal("Dataset generated from activity".format(activityID))))
        graph.add((URIRef(dataset), DC.publisher, Literal("ATTX HULib")))
        # graph.add((URIRef(dataset), DC.source, Literal()))
        # graph.add((URIRef(dataset), CC.license, ATTXOnto.CC0))
    return graph


def workflow_provenance(graph):
    """Generate workflow related provenance for link endpoint."""
    workflow_id = "_link"
    # There will be only one type of workflow and steps. Steps might differ in configuration.
    graph.add((URIRef("{0}workflow{1}".format(ATTXBase, workflow_id)), RDF.type, ATTXOnto.Workflow))
    graph.add((URIRef("{0}workflow{1}".format(ATTXBase, workflow_id)), DC.title, Literal("Linking Workflow")))
    graph.add((URIRef("{0}workflow{1}".format(ATTXBase, workflow_id)), DC.description, Literal("Workflow specific to the link GM API endpoint")))
    # Add predifined steps for the workflow
    generate_step(graph, 1, "Retrieve parameters", "Retrieve paramters for the linking for the specified strategy.", workflow_id)
    generate_step(graph, 2, "Construct linking graph", "Generate linking graph based on strategy parameters.", workflow_id)
    generate_step(graph, 3, "Add to graph store", "Add generated linking graph to the graph store.", workflow_id)
    graph.add((URIRef("{0}step{1}".format(ATTXBase, 1)), PWO.hasNextStep, URIRef("{0}step{1}".format(ATTXBase, 2))))
    graph.add((URIRef("{0}step{1}".format(ATTXBase, 2)), PWO.hasNextStep, URIRef("{0}step{1}".format(ATTXBase, 3))))

    app_logger.info('Construct activity metadata for Workflow: workflow{0} + associated steps.' .format(workflow_id))
    return graph


def generate_step(graph, stepID, title, description, workflow):
    """Generate step details."""
    graph.add((URIRef("{0}step{1}".format(ATTXBase, stepID)), RDF.type, ATTXOnto.Step))
    graph.add((URIRef("{0}step{1}".format(ATTXBase, stepID)), DC.title, Literal(title)))
    graph.add((URIRef("{0}step{1}".format(ATTXBase, stepID)), DC.description, Literal(description)))
    graph.add((URIRef("{0}workflow{1}".format(ATTXBase, workflow)), PWO.hasStep, URIRef("{0}step{1}".format(ATTXBase, stepID))))
    return graph
